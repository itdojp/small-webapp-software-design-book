name: Nav + Pages Link Check

on:
  schedule:
    - cron: '13 3 * * 1'
  workflow_dispatch: {}

jobs:
  nav-link-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install PyYAML
        run: python3 -m pip install --user pyyaml

      - name: Build URL list
        id: build
        run: |
          python3 - << 'PY'
          import os, yaml
          from pathlib import Path
          repo = os.environ.get('GITHUB_REPOSITORY','').split('/')[-1]
          cfg = Path('docs/_config.yml') if Path('docs/_config.yml').exists() else Path('_config.yml')
          baseurl = f'/{repo}'
          if cfg.exists():
              try:
                  data = yaml.safe_load(cfg.read_text(encoding='utf-8')) or {}
                  bu = data.get('baseurl')
                  if isinstance(bu,str) and bu.strip():
                      baseurl = bu.strip().strip('"\'')
              except Exception:
                  # Fallback to naive parse but strip quotes
                  for line in cfg.read_text(encoding='utf-8').splitlines():
                      if line.strip().startswith('baseurl:'):
                          val = line.split(':',1)[1].strip()
                          # Mirror the YAML-parsed path: trim whitespace then drop outer quotes.
                          baseurl = val.strip().strip('"\'').strip()
                          break
          if not baseurl.startswith('/'): baseurl = '/' + baseurl
          baseurl = baseurl.rstrip('/')

          def normalize_path(p):
              if not isinstance(p, str):
                  return None
              p = p.strip()
              if not p:
                  return None
              if p.startswith(('http://', 'https://', 'mailto:')):
                  return None
              if not p.startswith('/'):
                  p = '/' + p

              # Keep file-like paths as-is (e.g. /LICENSE.md). Otherwise, ensure trailing slash.
              if p.lower().endswith(('.md', '.html', '.htm', '.pdf', '.txt')):
                  return p
              return p if p.endswith('/') else p + '/'

          def read_nav():
              y = Path('docs/_data/navigation.yml')
              if not y.exists(): return []
              data = yaml.safe_load(y.read_text(encoding='utf-8')) or {}
              paths = []
              for key in ['introduction','chapters','additional','resources','appendices','afterword']:
                  for item in (data.get(key) or []):
                      # Some books structure chapters as parts: {part, items:[{title,path},...]}
                      if isinstance(item, dict) and isinstance(item.get('items'), list):
                          for sub in (item.get('items') or []):
                              if not isinstance(sub, dict):
                                  continue
                              p = normalize_path(sub.get('path'))
                              if p:
                                  paths.append(p)
                          continue
                      if not isinstance(item, dict):
                          continue
                      p = normalize_path(item.get('path'))
                      if p:
                          paths.append(p)
              return paths
          def discover():
              paths=[]
              for seg in ['introduction','chapters','additional','resources','appendices','afterword']:
                  d = Path('docs')/seg
                  if d.is_dir():
                      for child in sorted(d.iterdir()):
                          if child.is_dir(): paths.append(f'/{seg}/{child.name}/')
              return paths
          paths = read_nav() or discover() or ['/']
          # Always include index
          if '/' not in paths: paths.insert(0,'/')

          # De-dup while keeping order
          seen=set()
          uniq=[]
          for p in paths:
              if p in seen:
                  continue
              seen.add(p)
              uniq.append(p)
          paths=uniq

          base = f'https://itdojp.github.io{baseurl}'
          urls = [ (p, f"{base}{p}") for p in paths ]
          Path('urls.txt').write_text('\n'.join([f"{p}\t{u}" for p,u in urls]), encoding='utf-8')
          PY
          echo "list=urls.txt" >> $GITHUB_OUTPUT

      - name: Probe URLs
        run: |
          failures=0
          while IFS=$'\t' read -r path url; do
            code=$(curl -s -o /dev/null -w "%{http_code}" -L "$url")
            echo "$code $url"
            if [ "$code" != "200" ]; then failures=$((failures+1)); fi
          done < urls.txt
          if [ $failures -gt 0 ]; then echo "Found $failures non-200 URLs" >&2; exit 1; fi
